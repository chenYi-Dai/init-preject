server:
  port: 9009
spring:
  datasource:
    #url切换数据库之后如果对应数据库名称和路径有变动，需要修改url
    url: jdbc:mysql://9.134.94.134:3306/test?useUnicode=true&characterEncoding=utf-8&useSSL=false
    username: root
    password: ProjectFuture@2024
    driver-class-name: com.mysql.cj.jdbc.Driver
    type: com.zaxxer.hikari.HikariDataSource
  activiti:
    # 自动部署验证设置：true-开启（默认）、false-关闭
    check-process-definitions: false
    # 保存历史数据
    history-level: full
    # 检测历史表是否存在
    db-history-used: true
    # 关闭自动部署
    deployment-mode: never-fail
    # 对数据库中所有表进行更新操作，如果表不存在，则自动创建
    # create_drop：启动时创建表，在关闭时删除表（必须手动关闭引擎，才能删除表）
    # drop-create：启动时删除原来的旧表，然后在创建新表（不需要手动关闭引擎）
    database-schema-update: true
    # 解决频繁查询SQL问题
    async-executor-activate: false

  application:
    name: initial-project # 定义当前服务名称
#  cloud:
#    nacos:
#      discovery:
#        server-addr: 47.106.146.101:8848 # 指定正在运行的Nacos服务器的位置
  kafka:
    bootstrap-servers: 9.134.238.192:9092 #这个是kafka的地址,对应你server.properties中配置的
    producer:
      batch-size: 16384 #批量大小
      acks: -1 #应答级别:多少个分区副本备份完成时向生产者发送ack确认(可选0、1、all/-1)
      retries: 10 # 消息发送重试次数
      #transaction-id-prefix: transaction
      buffer-memory: 33554432
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      properties:
        linger:
          ms: 2000 #提交延迟
          #partitioner: #指定分区器
          #class: pers.zhang.config.CustomerPartitionHandler
    consumer:
      bootstrap-servers: 9.134.238.192:9092
      group-id: testGroup #默认的消费组ID
      enable-auto-commit: true #是否自动提交offset
      auto-commit-interval: 2000 #提交offset延时
      # 当kafka中没有初始offset或offset超出范围时将自动重置offset
      # earliest:重置为分区中最小的offset;
      # latest:重置为分区中最新的offset(消费分区中新产生的数据);
      # none:只要有一个分区不存在已提交的offset,就抛出异常;
      auto-offset-reset: latest
      max-poll-records: 500 #单次拉取消息的最大条数
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      properties:
        session:
          timeout:
            ms: 120000 # 消费会话超时时间（超过这个时间 consumer 没有发送心跳，就会触发 rebalance 操作）
        request:
          timeout:
            ms: 18000 # 消费请求的超时时间
    listener:
      missing-topics-fatal: false # consumer listener topics 不存在时，启动项目就会报错
    template:
      default-topic: test-topic-name
  #      type: batch
stop:
  case: false

